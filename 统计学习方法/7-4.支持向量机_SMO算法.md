SVM快速学习算法—SMO序列最小最优化算法，sequential minimal optimization算法

原理：将原二次规划问题分解为两个变量的二次规划子问题，并对子问题进行解析求解，直到所有变量满足KKT条件。

**SMO算法**

输入训练集和精度$\epsilon$，输出近似解$\hat{\alpha}$

①.取初值$\alpha^{(0)}=0$,令$k=0$;

②.选取优化变量$\alpha_{1}^{(k)}, \alpha_{2}^{(k)}$，解析求解两个变量的最优化问题，求得最优解$\alpha_{1}^{(k+1)}, \alpha_{2}^{(k+1)}$,更新$\alpha$为$\alpha^{(k+1)}$;

③.在精度$\epsilon$范围内满足停机条件
$$
\begin{aligned}
&\sum_{i=1}^{N} \alpha_{i} y_{i}=0\\
&0 \leqslant \alpha_{i} \leqslant C, \quad i=1,2, \cdots, N\\
&y_{i} \cdot g\left(x_{i}\right)=\left\{\begin{array}{ll}
\geqslant 1, & \left\{x_{i} | \alpha_{i}=0\right\} \\
=1, & \left\{x_{i} | 0<\alpha_{i}<C\right\} \\
\leqslant 1, & \left\{x_{i} | \alpha_{i}=C\right\}
\end{array}\right.
\end{aligned}\\
g\left(x_{i}\right)=\sum_{j=1}^{N} \alpha_{j} y_{j} K\left(x_{j}, x_{i}\right)+b
$$
如果$g\left(x_{i}\right)=\sum_{j=1}^{N} \alpha_{j} y_{j} K\left(x_{j}, x_{i}\right)+b$，那么转④，否则转②。

④取$\hat{\alpha}=\alpha^{(k+1)}$。