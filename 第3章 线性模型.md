# 3.线性模型
1.线性模型。  
2.权重向量。  
3.线性回归。  
4.决策函数。  
5.判别函数。  
6.符号函数。   
## 3.1线性判别函数和决策边界
1.线性分类模型。  
### 3.1.1两类分类
1.两类分类。    
2.分割超平面，决策边界，决策平面。  
3.有向距离。  
### 3.1.2多类分类
1.多类分类。   
2.一对其余方式。  
3.一对一方式。  
4.argmax方式。  
## 3.2Logistic回归
1.处理二分类问题。  
2.激活函数。  
3.联系函数。  
4.几率：样本x为正反例后验概率的比值。    
5.对数几率：几率的对数。       
6.对数几率回归。  
### 3.2.1参数学习
1.损失函数：交叉熵。    
2.参数优化：梯度下降法。    
## 3.3Softmax回归
1.处理多分类问题。  
2.决策函数。  
### 3.3.1参数学习
1.损失函数：交叉熵。  
2.参数优化：梯度下降法。    
## 3.4感知器 
### 3.4.1参数学习
1.激活函数、权重、偏置。  
2.损失函数。  
3.优化算法：梯度下降。  
### 3.4.2感知器的收敛性
### 3.4.5参数平均感知器
1.投票感知器。   
2.平均感知器。 
### 3.4.4扩展到多类分类
1.广义感知器的收敛性。  
## 3.5支持向量机
1.间隔：数据集中所有样本到分割超平面的最短距离。  
### 3.5.1参数学习
1.损失函数。  
2.支持向量。  
### 3.5.2核函数
1.核函数，核技巧。  
隐式地将样本从原始特征空间映射到更高维的空间，解决原始特征空间的线性不可分问题。 
### 3.5.3软间隔
1.软间隔：经验风险+正则化项。  
2.Hinge损失函数。
## 3.6损失函数对比
1.Logistic回归、感知器、支持向量机三者的决策函数相同，损失函数不同。
## 3.7总结和深入阅读
### 常见线性模型的激活函数，损失函数，优化算法。
1.线性回归，无激活函数，真实值和预测值的平方损失，最小二乘法和梯度下降法。    
2.Logistic回归，sgn激活函数，真实值和预测值的交叉熵损失，梯度下降法。  
3.Softmax回归，sgn激活函数，真实值和预测值的交叉熵损失，梯度下降法。  
4.感知器，sgn激活函数，预测值和真实值的0-1损失，随机梯度下降。  
5.支持向量机，sgn激活函数，预测值和真实值的hinge损失，二次规划、SMO优化。  

## 问题
1.0-1损失和感知损失的区别。
2.平方损失函数不适合分类的原因。
3.支持向量机的决策函数只依赖支持向量与训练样本总数无关的原因。






