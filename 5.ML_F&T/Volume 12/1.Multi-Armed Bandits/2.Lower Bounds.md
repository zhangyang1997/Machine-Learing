**Lower Bounds**

**简介**(35-36)

+ 35页段1：这一章内容讲的是赌博机算法不能解决的问题。

+ 35页段2：如何求出所有赌博机算法regret的下界？如何证明$\Omega(\sqrt{(KT)})$是算法regret的下界？如何求出实例依赖的regret下界$\Omega(logT)$？通过下界如何得到希望达到的最好上界？

+ 说明1：regret上界形式为$C\cdot f(T)$，$f(\cdot)$与$\mu$无关，$C$与$T$无关。如果$C$和$\mu$无关，称为实例独立；否成称为实例依赖。

+ 35页定理2.1：一个随机多臂赌博机，选择轮数为$T$，arm数量为$K$，对于任意一个赌博机算法，存在一个问题实例满足$E [R(T)] \geq \Omega(\sqrt{K T})$.

+ 35页说明：定理2.1的下界是最坏情况，因为可能有许多实例的regret比$\Omega(\sqrt{(KT)})$小；为了证明定理2.1，构造一个问题实例的集合$F$，问题实例能欺骗任何算法；证明定理2.1可以描述为：

  + ①证明任意算法对$F$中的某些实例都有很高的regret。
  + ②定义一个随机的问题实例是一个$F$上的分布。然后证明任意算法都对这个分布有很高的regret期望。

+ 36页Remark2.1：用②说明①，如果任意算法都对一个问题实例的分布有很高的regret期望，那么会存在一个高regret的问题实例。用①说明②，如果$|F|$是确定的常量，即任意算法对一些问题实例有很高的regret，那么期望regret最小为$\frac{H}{|F|}$，但是$|F|$很大就不成立。

  + ①更严格的说法是，对于$F$中的固定一部分的实例，regret很高；那么可以说明②是不管$|F|$多大，regret在所有实例上均匀分布。

+ 36页中间例子：带有问题实例的0-1reward分布满足下面公式：
  $$
  I _{j}=\left\{\begin{array}{ll}
  \mu_{i}=(1+\epsilon) / 2 & \text { arm } i=j \\
  \mu_{i}=1 / 2 & \text { 其他arm } i \neq j
  \end{array}\right.
  $$

  + 符号说明：
    + $i$和$j$是arm的序号。
    + $\mu_i$是arm$i$的reward。
    + 参数$\epsilon>0$
  + reward分布说明：选中一个arm$j$，arm$j$的reward增加$\frac{1+\epsilon}{2}$，其他arm的reward增加$\frac{1}{2}$.
  + 上一章的公式1.7结论是每个arm采用$\Omega(1/\epsilon^{2})$次可以得到regret上界。
  + 现在需要证明每个arm采用$\Omega(1/\epsilon^{2})$次才能判断这个arm的好坏，然后得出regret为$\Omega(K/\epsilon)$，通过代入$\epsilon=\Theta(\sqrt{(K/T)}$完成证明。这个证明非常巧妙。

**1.Bacground on KL-divergence**(37-38)

+ KL散度：两种概率分布之间差异的期望。

  + 符号说明

    + 有限样本空间为$\Omega$
    + 在$\Omega$上有两个概率分布$p$和$q$

  + 公式

    + $$
      KL (p, q)=\sum_{x \in \Omega} p(x) \ln \frac{p(x)}{q(x)}= E _{p}\left[\ln \frac{p(x)}{q(x)}\right]
      $$

+ Remark2.2：KL散度的定义和性质可以推广到无限样本空间，但是我们只用到了有限样本空间的定义和性质。

+ Remark2.3：有一个有限样本空间$x_1,...,x_n\in \Omega$，满足一个未知分布$p^{*}$。假设这个分布是$p$或者是$q$，通过样本和分布的对数似然比判断$p^{*}$是$p$还是$q$。

  + 对数似然比：

    + $$
      \Lambda_{n}:=\sum_{i=1}^{n} \frac{\log p\left(x_{i}\right)}{\log q\left(x_{i}\right)}
      $$

    + 如果对数似然比越大，$p^{*}$更可能是$p$。

    + 

  + 假设真实分布为$p$，当$n->∞$时，KL散度是对数似比的期望，即：

    + $$
      \lim _{n \rightarrow \infty} \Lambda_{n}= E \left[\Lambda_{n}\right]= KL (p, q) \quad \text { if } p^{*}=p
      $$

  + 符号说明：
    
    + 0-1分布的偏置随机量为$RC_\epsilon=\epsilon/2$

+ 38页定理2.2：KL散度的性质

  + 吉布斯不等式：对于任意两个分布$p,q$，当且仅当$p = q$时，$KL (p,q)≥0$。
  + 乘积分布的链式法则： $\Omega=\Omega_{1} \times \Omega_{1} \times \cdots \times \Omega_{n} $， $p=p_{1} \times p_{2} \times \cdots \times p_{n}$ ， $q=$ $q_{1} \times q_{2} \times \cdots \times q_{n}$，$p_{j}, q_{j}$ 是$\Omega_{j}$的分布，那么$KL (p, q)=\sum_{j=1}^{n} KL \left(p_{j}, q_{j}\right)$。
  + 皮斯科克不等式：对于任意事件$A\subset \Omega$，满足$2(p(A)-q(A))^{2} \leq KL (p, q)$
  + 随机coin：$ KL \left( RC _{\epsilon}, RC _{0}\right) \leq 2 \epsilon^{2}, \text { 且 } KL \left( RC _{0}, RC _{\epsilon}\right) \leq \epsilon^{2} \text { 对任意 }
    \epsilon \in\left(0, \frac{1}{2}\right)$

+ 对于$n$样本有两个随机coin：第一个是有偏的随机coin满足分布$p_j=RC_\epsilon$，第二个是无偏的随机coin满足分布$q_j$，其中$j\in[n]$，假设存在一个事件$A \subset \Omega$，如何证明当$\epsilon$很小时，$p(A)和$q(A)$很接近？

  + 根据KL散度性质得到：

  + $$
    \begin{aligned}
    2(p(A)-q(A))^{2} & \leq \operatorname{KL}(p, q) ----- 皮斯克不等式\\
    &=\sum_{j=1}^{n} KL \left(p_{j}, q_{j}\right) ----链式法则\\
    & \leq n \cdot KL \left( RC _{\epsilon}, RC _{0}\right) ---p,q分布的定义\\
    & \leq 2 n \epsilon^{2}----随机coin的性质
    \end{aligned}
    $$

  + $$
    所以得到|p(A)-q(A)| \leq \epsilon \sqrt{n} \\
    特别的当\epsilon<\frac{1}{2 \sqrt{n}}，|p(A)-q(A)|<\frac{1}{2}
    $$

+ 39页引理2.3：一个样本空间$\Omega=\{0,1\}^{n}$，两个在$\Omega$上的分布$p=RC_\epsilon^{n}$和$q=RC_0^{n}$，当$\epsilon>0$，对于任意$A\subset \Omega$，满足$|p(A)-q(A)| \leq \epsilon \sqrt{n}$.

+ 注意：KL散度不满足对称性，这个性质我们不去讨论。

**2.A simple example：flipping one coin**(39)

+ 考虑一个biased random coin：一个分布在$\{0,1\}$上，未知均值$\mu\in [0,1]$，假设$\mu\in\{\mu_1,\mu_2\}$，且$\mu_1>\mu_2$。coin被抛T次，如何确定$\mu$使误差概率最小？

+ 定义一个决策规则和规则满足的条件：

  + Rule：$\Omega=\{0,1\}^{T}->\{High,Low\}$

  + $$
    \begin{array}{l}
    \operatorname{Pr}\left[\text { Rule (观测值) }=\text { High } | \mu=\mu_{1}\right] \geq 0.99 \\
    \operatorname{Pr}\left[\text { Rule (观测值) }=\operatorname{Low} | \mu=\mu_{2}\right] \geq 0.99
    \end{array}
    $$

  + 对于上面的决策规则，T应该多大？我们知道$T\text{~}(\mu_1-\mu_2)^{-2}$是足够的。我们关心的是$\mu_1,\mu_2$都接近$\frac{1}{2}$

+ 39页引理2.4：$\mu_{1}=\frac{1+\epsilon}{2}$ ， $\mu_{2}=\frac{1}{2} .$ 满足上面决策规则和规则满足的条件，$T>\frac{1}{4\epsilon^{2}}$.

  + 证明：令事件$A_{0} \subset \Omega$ 返回 High，然后有
    $$
    \operatorname{Pr}\left[A_{0} | \mu=\mu_{1}\right]-\operatorname{Pr}\left[A_{0} | \mu=\mu_{2}\right] \geq 0.98
    $$
    令$P_{i}(A)=\operatorname{Pr}\left[A | \mu=\mu_{i}\right],$ 对于任意事件 $A \subset \Omega$ 且每一个 $i \in\{1,2\} $。

    如果$\mu=\mu_{i} $，有$P_{i}=P_{i, 1} \times \ldots \times P_{i, T},$ 其中 $P_{i, t}$ 第 $t$ 次抛coin的分布，所以引理2.3关于KL散度的结论适用于是 $P_{1}$ 和$P_{2}$ 分布，可得 $\left|P_{1}(A)-P_{2}(A)\right| \leq \epsilon \sqrt{T} .$ 当$A=A_{0}$ 且 $T \leq \frac{1}{4 \epsilon^{2}},$ 得到$\left|P_{1}\left(A_{0}\right)-P_{2}\left(A_{0}\right)\right|<\frac{1}{2},$ 与引理2.4矛盾。

**3.Flipping several coins："besr-arm identification"**(40-42)

+ 40页第一段：将前面的示例扩展到多个coin。考虑一个有K个arm的赌博机问题，其中每个arm都是一个有偏的随机硬币，其均值未知。每个arm的reward独立于一个固定的但未知的伯努利分布来。经过T轮后，算法输出一个预测的最优arm $y_T$。我们只关心预测的quality，而不是regret。

+ 符号说明：

  + arm的集合为$[K]$
  + arm $a$的平均reward为$\mu(a)$，
  + 一个问题实例为元组$I=(\mu(a):a\in [K]).$

+ 好的best-arm选择算法应该对于任意问题实例都满足  
  $$
  \operatorname{Pr}\left[\text { prediction } y_{T} \text { is correct } | I \right] \geq 0.99
  $$
  且需要满足$T>\Omega(K/\epsilon^{2})$

**4.Proof of Lemma 2.5 for K24 arms**(43-45)

**5.Instance-dependent lower bounds**(45-47)